"""graph.py â€” ç”¨ LangGraph StateGraph å®ç° ReAct å†³ç­–å±‚ã€‚

=== LangGraph ç‰ˆ ReAct çš„æ ¸å¿ƒæ€è·¯ ===

æŠŠæ‰‹å†™çš„ while å¾ªç¯æ‹†è§£æˆå›¾çš„ä¸‰è¦ç´ ï¼š
  1. èŠ‚ç‚¹ (Nodes): agentï¼ˆè°ƒç”¨ LLMï¼‰ã€toolsï¼ˆæ‰§è¡Œå·¥å…·ï¼‰
  2. æ¡ä»¶è¾¹ (Conditional Edge): should_continue åˆ¤æ–­èµ°å“ªæ¡è·¯
  3. å¾ªç¯è¾¹ (Loop Edge): tools â†’ agentï¼ŒæŠŠå·¥å…·ç»“æœåé¦ˆç»™ LLM

                   â”Œâ”€â”€â”€â”€â”€â”€â”
     START â”€â”€â”€â”€â”€â”€â–¶â”‚ agent â”‚
                   â””â”€â”€â”¬â”€â”€â”€â”˜
                      â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                â–¼
       has tool_calls     no tool_calls
              â”‚                â”‚
              â–¼                â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”          END
         â”‚ tools  â”‚
         â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
             â”‚
             â””â”€â”€â”€â”€â”€â”€â–¶ agent (å¾ªç¯)
"""

import os
from typing import Annotated, Sequence, Literal
from typing_extensions import TypedDict

from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, ToolMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from dotenv import load_dotenv

from .tools import ALL_TOOLS

load_dotenv()

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Step 1: å®šä¹‰çŠ¶æ€ (State)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#
# State æ˜¯å›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹å…±äº«çš„"é»‘æ¿"ã€‚
# add_messages æ˜¯ LangGraph æä¾›çš„ reducer â€”â€” å®ƒæŠŠæ–°æ¶ˆæ¯è¿½åŠ åˆ°åˆ—è¡¨ï¼Œ
# è€Œä¸æ˜¯è¦†ç›–ï¼Œè¿™æ ·å¯¹è¯å†å²å°±èƒ½è‡ªåŠ¨ç´¯ç§¯ã€‚


class AgentState(TypedDict):
    """ReAct Agent çš„çŠ¶æ€ã€‚

    - messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼ˆå« Human / AI / Tool æ¶ˆæ¯ï¼‰
    - iteration: å½“å‰å¾ªç¯æ¬¡æ•°ï¼ˆå®‰å…¨é˜€ï¼‰
    """
    messages: Annotated[Sequence[BaseMessage], add_messages]
    iteration: int


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Step 2: åˆå§‹åŒ– LLM + ç»‘å®šå·¥å…·
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

AGENT_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªç½‘é¡µå†…å®¹æŠ“å–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ç»™å®šçš„ URL è·å–é«˜è´¨é‡çš„è‹±æ–‡æ­£æ–‡ã€‚

## ç­–ç•¥ï¼ˆè¯·æ ¹æ® URL ç±»å‹é€‰æ‹©ï¼‰

### RFC æ–‡æ¡£
å¦‚æœ URL åŒ…å« "rfc" å’Œæ•°å­—ï¼ˆå¦‚ rfc7519ã€#rfc7519ï¼‰ï¼š
1. **ä¼˜å…ˆä½¿ç”¨ `fetch_rfc_direct`**ï¼Œç›´æ¥ä» IETF å®˜æ–¹æºæŠ“å–
2. ä» URL ä¸­æå– RFC ç¼–å·ï¼ˆå¦‚ä» "#rfc7519" æå– "7519"ï¼‰
3. å¦‚æœå¤±è´¥ï¼Œå†å°è¯•å…¶ä»–æ–¹æ³•

### æ™®é€šç½‘é¡µ
1. å…ˆç”¨ `fetch_static` å·¥å…·å°è¯•é™æ€æŠ“å–
2. å¦‚æœè¿”å›å†…å®¹åŒ…å« [WARN] æˆ– [ERROR]ï¼Œæ”¹ç”¨ `fetch_dynamic` è¿›è¡Œæµè§ˆå™¨æ¸²æŸ“æŠ“å–
3. å¦‚æœæŠ“å–åˆ°çš„æ˜¯ JavaScript ä»£ç è€Œéæ­£æ–‡ï¼Œè¯´æ˜é¡µé¢éœ€è¦ç‰¹æ®Šå¤„ç†

## æ³¨æ„
- æœ€ç»ˆå¿…é¡»è¿”å›æŠ“å–åˆ°çš„çº¯æ–‡æœ¬æ­£æ–‡
- ä¸è¦ç¼–é€ å†…å®¹
- æœ€å¤šå°è¯• 3 æ¬¡å·¥å…·è°ƒç”¨
- å¦‚æœæŠ“å–åˆ°çš„å†…å®¹åŒ…å«å¤§é‡ JavaScript å‡½æ•°æˆ–ä»£ç ï¼Œè¯´æ˜æŠ“å–ç­–ç•¥ä¸å¯¹
"""


def create_llm():
    """åˆ›å»º LLM å®ä¾‹ï¼Œæ”¯æŒè‡ªç­¾åè¯ä¹¦çš„æœ¬åœ°éƒ¨ç½²ã€‚"""
    api_key = os.getenv("LLM_API_KEY", "")
    base_url = os.getenv("LLM_BASE_URL", "")
    model = os.getenv("LLM_MODEL", "gpt-4o-mini")
    disable_ssl = os.getenv("DISABLE_SSL_VERIFY", "false").lower() == "true"

    # é…ç½® httpx å®¢æˆ·ç«¯ä»¥æ”¯æŒè‡ªç­¾åè¯ä¹¦
    import httpx
    http_client = httpx.Client(verify=not disable_ssl) if disable_ssl else None
    http_async_client = httpx.AsyncClient(verify=not disable_ssl) if disable_ssl else None

    kwargs = {
        "model": model,
        "temperature": 0,
    }

    if api_key:
        kwargs["openai_api_key"] = api_key

    if base_url:
        kwargs["openai_api_base"] = base_url

    if http_client:
        kwargs["http_client"] = http_client

    if http_async_client:
        kwargs["http_async_client"] = http_async_client

    return ChatOpenAI(**kwargs)


# å»¶è¿Ÿåˆå§‹åŒ– LLMï¼Œé¿å…åœ¨å¯¼å…¥æ—¶å°±è¦æ±‚ API key
_llm = None
_llm_with_tools = None


def get_llm():
    """è·å– LLM å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
    global _llm
    if _llm is None:
        _llm = create_llm()
    return _llm


def get_llm_with_tools():
    """è·å–ç»‘å®šå·¥å…·çš„ LLM å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
    global _llm_with_tools
    if _llm_with_tools is None:
        _llm_with_tools = get_llm().bind_tools(ALL_TOOLS)
    return _llm_with_tools


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Step 3: å®šä¹‰èŠ‚ç‚¹ (Nodes)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def agent_node(state: AgentState) -> dict:
    """ğŸ§  Agent èŠ‚ç‚¹ = ReAct ä¸­çš„ Reason æ­¥éª¤ã€‚

    è¯»å–æ¶ˆæ¯å†å² â†’ è°ƒç”¨ LLM â†’ è¿”å›å†³ç­–ç»“æœã€‚
    LLM å¯èƒ½è¿”å›ï¼š
      - å¸¦ tool_calls çš„ AIMessage â†’ éœ€è¦æ‰§è¡Œå·¥å…·
      - çº¯æ–‡æœ¬çš„ AIMessage â†’ å·²æœ‰ç»“è®ºï¼Œå¯ä»¥ç»“æŸ
    """
    messages = state["messages"]

    # ç¡®ä¿ç³»ç»Ÿæç¤ºåœ¨æœ€å‰é¢
    if not messages or not isinstance(messages[0], SystemMessage):
        messages = [SystemMessage(content=AGENT_SYSTEM_PROMPT)] + list(messages)

    # è°ƒç”¨ LLMï¼ˆè¿™é‡Œå°±æ˜¯ Reasonï¼ï¼‰
    response = get_llm_with_tools().invoke(messages)

    # æ›´æ–°è¿­ä»£è®¡æ•°
    iteration = state.get("iteration", 0) + 1
    print(f"  ğŸ§  [agent èŠ‚ç‚¹] ç¬¬ {iteration} è½®æ¨ç†å®Œæˆ")

    if response.tool_calls:
        for tc in response.tool_calls:
            print(f"     â†’ å†³å®šè°ƒç”¨å·¥å…·: {tc['name']}({tc['args']})")
    else:
        print(f"     â†’ å¾—å‡ºç»“è®ºï¼Œå‡†å¤‡ç»“æŸ")

    return {
        "messages": [response],
        "iteration": iteration,
    }


# ToolNode: LangGraph é¢„æ„å»ºçš„å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹ã€‚
# å®ƒè‡ªåŠ¨è§£æ AIMessage ä¸­çš„ tool_callsï¼Œæ‰§è¡Œå¯¹åº”å·¥å…·ï¼Œ
# ç„¶åæŠŠç»“æœåŒ…è£…æˆ ToolMessage è¿”å›ã€‚
# è¿™å°±æ˜¯ ReAct ä¸­çš„ Act + Observeï¼
tools_node = ToolNode(ALL_TOOLS)


def tool_node_with_logging(state: AgentState) -> dict:
    """ğŸ”§ å·¥å…·èŠ‚ç‚¹ + æ—¥å¿—ã€‚åŒ…è£… ToolNode æ·»åŠ æ‰“å°ã€‚

    è¿™é‡Œå±•ç¤ºäº†å¦‚ä½•åœ¨ LangGraph çš„é¢„æ„å»ºèŠ‚ç‚¹å¤–åŒ…ä¸€å±‚è‡ªå®šä¹‰é€»è¾‘ã€‚
    """
    result = tools_node.invoke(state)

    # æ‰“å° Observation é¢„è§ˆ
    for msg in result["messages"]:
        if isinstance(msg, ToolMessage):
            preview = msg.content[:150].replace("\n", " ")
            print(f"  ğŸ‘ï¸  [tools èŠ‚ç‚¹] Observation: {preview}...")

    return result


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Step 4: å®šä¹‰æ¡ä»¶è¾¹ (Conditional Edge)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

MAX_ITERATIONS = 5


def should_continue(state: AgentState) -> Literal["tools", "__end__"]:
    """æ¡ä»¶è·¯ç”±å‡½æ•°ï¼šå†³å®šä¸‹ä¸€æ­¥èµ°å“ªä¸ªèŠ‚ç‚¹ã€‚

    è¿™ä¸ªå‡½æ•°å°±æ˜¯ ReAct å¾ªç¯çš„"å²”è·¯å£"ï¼š
      - å¦‚æœ LLM è¿”å›äº† tool_calls â†’ èµ° tools èŠ‚ç‚¹ï¼ˆç»§ç»­å¾ªç¯ï¼‰
      - å¦‚æœæ²¡æœ‰ tool_calls â†’ èµ° ENDï¼ˆç»“æŸå¾ªç¯ï¼‰
      - å¦‚æœè¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•° â†’ å¼ºåˆ¶ ENDï¼ˆå®‰å…¨é˜€ï¼‰
    """
    messages = state["messages"]
    last_message = messages[-1]
    iteration = state.get("iteration", 0)

    # å®‰å…¨é˜€ï¼šé˜²æ­¢æ— é™å¾ªç¯
    if iteration >= MAX_ITERATIONS:
        print(f"  âš ï¸  è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {MAX_ITERATIONS}ï¼Œå¼ºåˆ¶ç»“æŸ")
        return "__end__"

    # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æœ‰ tool_callsï¼Œèµ° tools èŠ‚ç‚¹
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"

    # å¦åˆ™èµ° END
    return "__end__"


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Step 5: ç»„è£…å›¾ (Build the Graph)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def build_fetch_graph():
    """æ„å»º ReAct æŠ“å–å›¾ã€‚

    å›¾çš„ç»“æ„ï¼š
        START â†’ agent â†’ (should_continue?) â†’ tools â†’ agent â†’ ... â†’ END
    """
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(AgentState)

    # â”€â”€ æ·»åŠ èŠ‚ç‚¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    workflow.add_node("agent", agent_node)       # ğŸ§  æ¨ç†èŠ‚ç‚¹
    workflow.add_node("tools", tool_node_with_logging)  # ğŸ”§ å·¥å…·èŠ‚ç‚¹

    # â”€â”€ æ·»åŠ è¾¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å…¥å£è¾¹ï¼šSTART â†’ agent
    workflow.add_edge(START, "agent")

    # æ¡ä»¶è¾¹ï¼šagent ä¹‹åæ ¹æ® should_continue çš„è¿”å›å€¼è·¯ç”±
    workflow.add_conditional_edges(
        "agent",              # æºèŠ‚ç‚¹
        should_continue,      # è·¯ç”±å‡½æ•°
        {                     # è·¯ç”±æ˜ å°„
            "tools": "tools",      # æœ‰ tool_calls â†’ å»æ‰§è¡Œå·¥å…·
            "__end__": END,        # æ—  tool_calls â†’ ç»“æŸ
        },
    )

    # å¾ªç¯è¾¹ï¼štools â†’ agentï¼ˆæŠŠå·¥å…·ç»“æœåé¦ˆç»™ LLM ç»§ç»­æ¨ç†ï¼‰
    workflow.add_edge("tools", "agent")

    # â”€â”€ ç¼–è¯‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    graph = workflow.compile()

    return graph


# â”€â”€ æ„å»ºå…¨å±€å®ä¾‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

fetch_graph = build_fetch_graph()
